---
title: "A Hitchhiker’s Guide to Scaling Law Estimation"
author: "Aakash Kumar Nain ([@A_K_Nain](https://x.com/A_K_Nain))"
date: "2024-11-04"
categories: [papers, summary, research, transformers, scaling]
image: ""
format:
  html:
    theme: default
    fontsize: 2em
    backgroundcolor: rgb(255, 255, 255);
    code-fold: true
    code-summary: "Show the code"
    highlight-style: oblivion
    css: styles.css
execute: 
  echo: false
---

[arXiv](https://arxiv.org/abs/2410.11840)<br>


Scaling laws have been discussed a lot in the past few years. The OG paper 
on scaling laws is still one of the best, but this latest paper from IBM and MIT provides
a fresh perspective. Here is a quick summary in case you are interested:


# Why should one care about scaling laws?

* Design choices like architectural modification, data changes, etc., are crucial, but every
option is expensive to evaluate at scale.
* What if we use smaller models to assess the design choices? Will the findings be upheld when
using a larger model?
* A scaling law extrapolates the performance of a target model from the performance of a set
of models with fewer parameters or smaller training sets. A high-quality scaling law
accurately predicts the test performance of the target model.

<br>

# Defining a scaling law

* A scaling law estimates the loss of a costly model by training cheaper ones that share
a pretraining procedure and differ by some hyperparameters, typically model size (num_params)
and number of tokens seen during training (num_toks).
* The authors define a scaled model family *f* as a set of models, with each f ∈ F differing
only in size num_params(f ) and number of tokens num_toks(f ).
* They divide this into subsets. First, the maximal parameter family max params (F)
containing models in F with the largest number of parameters. This family will generally
include the target model(s) whose behavior we wish to predict t ∈ F~target~. Second, the
q-maximal token family max num_toks (F, q) contains all models in *f* trained on at least
a q-sized fraction of the training set.
* A scaling law *L(f | F )* estimates the performance of a new model *f* given a model
family F and is defined as shown below:

<br><br>
![](../paper_screenshots/scaling_laws_estimation/1.png)
<br><br>

*E* is a baseline capturing the general performance of the scaled family. A and α describe
the scaling effect of num_params, while B and β describe the scaling effect of num_toks.
These parameters are estimated by first collecting a set of training models F~train~, then
minimizing the reconstruction error as shown above. *L(f )* denotes the empirical negative
log-likelihood of some held-out data under the model.


# How Well Can I Expect a Scaling Law to Predict?

* To estimate this, we need to know what is considered a meaningful change when comparing
two models (of the same family). The authors found that any design change that yields less
than a 4% change in performance has not been considered meaningful in the literature.
* Also, the variance across the same model with restarts reaches a 3.5% difference. Thus,
a 4% difference bounds the best goodness of fit we should expect or require of scaling laws.
* The **Absolute Relative Error (ARE)** is bounded by 4% and can reach 20% with certain
design choices.


<br><br>
![](../paper_screenshots/omniparser/2.png)
<br><br>




<br><br>
![](../paper_screenshots/omniparser/3.png)
<br><br>



<br><br>
![](../paper_screenshots/omniparser/4.png)
<br><br>

